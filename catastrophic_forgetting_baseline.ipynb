{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <EEB3232B-F6A7-3262-948C-BB2F54905803> /Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of task  0\n",
      "Classes in this task: [0, 1, 2, 7, 8]\n",
      "Task 0\n",
      "This task contains 30739 training examples\n",
      "This task contains 5149 test examples\n",
      "Start of task  0\n",
      "Classes in this task: [3, 4, 5, 6, 9]\n",
      "Task 0\n",
      "This task contains 29261 training examples\n",
      "This task contains 4851 test examples\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitMNIST\n",
    "\n",
    "benchmark = SplitMNIST(n_experiences=2)\n",
    "\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "for experience in train_stream: \n",
    "    print(\"Start of task \", experience.task_label)\n",
    "    print('Classes in this task:', experience.classes_in_this_experience)\n",
    "\n",
    "    current_training_set = experience.dataset\n",
    "    print('Task {}'.format(experience.task_label))\n",
    "    print('This task contains', len(current_training_set), 'training examples')\n",
    "\n",
    "    current_test_set = test_stream[experience.current_experience].dataset\n",
    "    print('This task contains', len(current_test_set), 'test examples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the file logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, \\\n",
    "    accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \\\n",
    "    confusion_matrix_metrics, disk_usage_metrics, StreamConfusionMatrix\n",
    "from avalanche.logging import InteractiveLogger\n",
    "\n",
    "text_logger = InteractiveLogger()\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    StreamConfusionMatrix(num_classes=benchmark.n_classes, save_image=False),\n",
    "    loggers=[text_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models and Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive, EWC\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "mlp_naive = SimpleMLP(num_classes=benchmark.n_classes)\n",
    "naive_strategy = Naive(\n",
    "    model = mlp_naive, \n",
    "    optimizer = SGD(mlp_naive.parameters(), lr=0.001, momentum=0.9),\n",
    "    criterion = CrossEntropyLoss(), \n",
    "    train_mb_size=500, \n",
    "    train_epochs=10, \n",
    "    eval_mb_size=100,\n",
    "    evaluator=eval_plugin)\n",
    "\n",
    "mlp_ewc = SimpleMLP(num_classes=benchmark.n_classes)\n",
    "ewc_strategy = EWC(\n",
    "    model = mlp_ewc, \n",
    "    optimizer = SGD(mlp_ewc.parameters(), lr=0.001, momentum=0.9),\n",
    "    criterion = CrossEntropyLoss(), \n",
    "    ewc_lambda = 2000,\n",
    "    train_mb_size=500, \n",
    "    train_epochs=10, \n",
    "    eval_mb_size=100,\n",
    "    evaluator=eval_plugin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience  0\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2072\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4758\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6856\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9038\n",
      "100%|██████████| 62/62 [00:04<00:00, 13.11it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3935\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3483\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9033\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8912\n",
      "100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2881\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2399\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9202\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9163\n",
      "100%|██████████| 62/62 [00:04<00:00, 14.24it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2479\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2102\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9267\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9289\n",
      "100%|██████████| 62/62 [00:04<00:00, 14.51it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2211\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2259\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9324\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9372\n",
      "100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2052\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2334\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9369\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9247\n",
      "100%|██████████| 62/62 [00:04<00:00, 13.18it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1940\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1626\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9397\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9498\n",
      "100%|██████████| 62/62 [00:04<00:00, 13.66it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1837\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1776\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9425\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9498\n",
      "100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1791\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1300\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9452\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9749\n",
      "100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1725\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1756\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9582\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 38.25it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1431\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9582\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[ 969,    0,    3,    0,    0,    0,    0,    1,    7,    0],\n",
      "        [   0, 1109,    7,    0,    0,    0,    0,    2,   17,    0],\n",
      "        [  15,    7,  954,    0,    0,    0,    0,   19,   37,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1,   16,   30,    0,    0,    0,    0,  974,    7,    0],\n",
      "        [   9,    6,   16,    0,    0,    0,    0,   15,  928,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1431\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9582\n",
      "Start of experience  1\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 59/59 [00:04<00:00, 12.11it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3730\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8170\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4516\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7739\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.26it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6459\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4897\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8230\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8889\n",
      "100%|██████████| 59/59 [00:05<00:00,  9.97it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4675\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4201\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8634\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8812\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.53it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3899\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3822\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8854\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8774\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.06it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3472\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3802\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8946\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8889\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.52it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3173\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2414\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9042\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9310\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.40it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2986\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2865\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9072\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9234\n",
      "100%|██████████| 59/59 [00:04<00:00, 12.22it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2793\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2537\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9142\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9272\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.25it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2665\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2649\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9161\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9157\n",
      "100%|██████████| 59/59 [00:04<00:00, 14.06it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2560\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2021\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9190\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9272\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 39.93it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2119\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9326\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0, 953,   3,  29,   4,   0,   0,  21],\n",
      "        [  0,   0,   0,   2, 929,   2,  15,   0,   0,  34],\n",
      "        [  0,   0,   0,  38,  12, 810,  21,   0,   0,  11],\n",
      "        [  0,   0,   0,   4,  17,  24, 913,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,  19,  48,  21,   2,   0,   0, 919]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.2119\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9326\n",
      "Final evaluation...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 41.03it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9489\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 5.7928\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0093\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 37.77it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2119\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9326\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,  35,   3, 879,  56,   0,   0,   7],\n",
      "        [  0,  48,   0, 990,   2,  81,  13,   0,   0,   1],\n",
      "        [  0,   0,   0, 632,  46,  31, 273,   0,   0,  50],\n",
      "        [  0,   0,   0, 953,   3,  29,   4,   0,   0,  21],\n",
      "        [  0,   0,   0,   2, 929,   2,  15,   0,   0,  34],\n",
      "        [  0,   0,   0,  38,  12, 810,  21,   0,   0,  11],\n",
      "        [  0,   0,   0,   4,  17,  24, 913,   0,   0,   0],\n",
      "        [  0,   0,   0,  72,  30,   3,   1,   0,   0, 922],\n",
      "        [  0,   0,   0, 353,  26, 425,  53,   0,   0, 117],\n",
      "        [  0,   0,   0,  19,  48,  21,   2,   0,   0, 919]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0855\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.9489\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9272030651340997,\n",
       " 'Loss_MB/train_phase/train_stream/Task000': 0.20209628343582153,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9190389938826424,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task000': 0.25599117917000264,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.009322198485142746,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp000': 5.7928380825422785,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.4572,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task000': 3.085521245234832,\n",
       " 'StreamForgetting/eval_phase/test_stream': 0.9489221208001554,\n",
       " 'ConfusionMatrix_Stream/eval_phase/test_stream': tensor([[  0,   0,   0,  35,   3, 879,  56,   0,   0,   7],\n",
       "         [  0,  48,   0, 990,   2,  81,  13,   0,   0,   1],\n",
       "         [  0,   0,   0, 632,  46,  31, 273,   0,   0,  50],\n",
       "         [  0,   0,   0, 953,   3,  29,   4,   0,   0,  21],\n",
       "         [  0,   0,   0,   2, 929,   2,  15,   0,   0,  34],\n",
       "         [  0,   0,   0,  38,  12, 810,  21,   0,   0,  11],\n",
       "         [  0,   0,   0,   4,  17,  24, 913,   0,   0,   0],\n",
       "         [  0,   0,   0,  72,  30,   3,   1,   0,   0, 922],\n",
       "         [  0,   0,   0, 353,  26, 425,  53,   0,   0, 117],\n",
       "         [  0,   0,   0,  19,  48,  21,   2,   0,   0, 919]]),\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.9325912183055041,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp001': 0.21189222126120982,\n",
       " 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp000': 0.9489221208001554}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_naive = []\n",
    "print('Starting experiment...')\n",
    "\n",
    "for exp_id, experience in enumerate(train_stream):\n",
    "    print(\"Start of experience \", experience.current_experience)\n",
    "\n",
    "    naive_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the current test set')\n",
    "    results_naive.append(naive_strategy.eval(benchmark.test_stream[exp_id]))\n",
    "\n",
    "print('Final evaluation...')\n",
    "naive_strategy.eval(benchmark.test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience  0\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.46it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2564\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5641\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6558\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8842\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.94it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4232\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3516\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8949\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9243\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.79it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3088\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2859\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9129\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9125\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.86it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2633\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2297\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9225\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9314\n",
      "100%|██████████| 61/61 [00:04<00:00, 12.43it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2391\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2044\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9272\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9433\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.21it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2211\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1789\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9327\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9456\n",
      "100%|██████████| 61/61 [00:04<00:00, 12.66it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2105\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2462\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9358\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9220\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.54it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1979\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1981\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9398\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9291\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.36it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1904\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2167\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9417\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9385\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.70it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1833\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1649\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9436\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9551\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 36.97it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1416\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9575\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[ 971,    0,    3,    0,    0,    0,    0,    0,    5,    1],\n",
      "        [   0, 1114,    6,    0,    0,    0,    0,    0,   13,    2],\n",
      "        [  15,   10,  953,    0,    0,    0,    0,    0,   37,   17],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [  11,    7,   17,    0,    0,    0,    0,    0,  908,   31],\n",
      "        [   9,    8,    7,    0,    0,    0,    0,    0,   19,  966]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1416\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9575\n",
      "Start of experience  1\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6450\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8660\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4709\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8701\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.47it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6075\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5457\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8784\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8312\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.17it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4180\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4184\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9010\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8961\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.13it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3498\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4623\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9138\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8571\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.32it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3142\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2360\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9191\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9481\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.78it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2896\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9243\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9221\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.98it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2729\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2892\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9288\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8961\n",
      "100%|██████████| 60/60 [00:05<00:00, 11.50it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2566\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2481\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9336\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9481\n",
      "100%|██████████| 60/60 [00:05<00:00, 11.17it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2463\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2632\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9339\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9221\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.41it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2365\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2108\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9381\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9221\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 35.71it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1650\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9509\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0, 955,   2,  23,   4,  26,   0,   0],\n",
      "        [  0,   0,   0,   1, 955,   3,  16,   7,   0,   0],\n",
      "        [  0,   0,   0,  43,  16, 811,  18,   4,   0,   0],\n",
      "        [  0,   0,   0,   4,  12,  17, 924,   1,   0,   0],\n",
      "        [  0,   0,   0,  26,  14,   0,   2, 986,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1650\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9509\n",
      "Final evaluation...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 32.67it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.8493\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.9334\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1082\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 38.22it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1650\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9509\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,  40,   1, 836,  96,   7,   0,   0],\n",
      "        [  0, 497,   0, 468,   6,  37,  11, 116,   0,   0],\n",
      "        [  0,   0,  58, 523,  65,  32, 304,  50,   0,   0],\n",
      "        [  0,   0,   0, 955,   2,  23,   4,  26,   0,   0],\n",
      "        [  0,   0,   0,   1, 955,   3,  16,   7,   0,   0],\n",
      "        [  0,   0,   0,  43,  16, 811,  18,   4,   0,   0],\n",
      "        [  0,   0,   0,   4,  12,  17, 924,   1,   0,   0],\n",
      "        [  0,   0,   0,  26,  14,   0,   2, 986,   0,   0],\n",
      "        [  0,   0,   0, 326,  37, 532,  41,  38,   0,   0],\n",
      "        [  0,   0,   0,  25, 681,  34,   4, 265,   0,   0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.0982\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.8493\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Top1_Acc_MB/train_phase/train_stream/Task000': 0.922077922077922,\n",
       " 'Loss_MB/train_phase/train_stream/Task000': 0.21081849932670593,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9380599790377658,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task000': 0.23651596240989736,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.10818713450292397,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp000': 3.9334067754578173,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.5186,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task000': 2.0981782685741783,\n",
       " 'StreamForgetting/eval_phase/test_stream': 0.849317738791423,\n",
       " 'ConfusionMatrix_Stream/eval_phase/test_stream': tensor([[  0,   0,   0,  40,   1, 836,  96,   7,   0,   0],\n",
       "         [  0, 497,   0, 468,   6,  37,  11, 116,   0,   0],\n",
       "         [  0,   0,  58, 523,  65,  32, 304,  50,   0,   0],\n",
       "         [  0,   0,   0, 955,   2,  23,   4,  26,   0,   0],\n",
       "         [  0,   0,   0,   1, 955,   3,  16,   7,   0,   0],\n",
       "         [  0,   0,   0,  43,  16, 811,  18,   4,   0,   0],\n",
       "         [  0,   0,   0,   4,  12,  17, 924,   1,   0,   0],\n",
       "         [  0,   0,   0,  26,  14,   0,   2, 986,   0,   0],\n",
       "         [  0,   0,   0, 326,  37, 532,  41,  38,   0,   0],\n",
       "         [  0,   0,   0,  25, 681,  34,   4, 265,   0,   0]]),\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.9509240246406571,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp001': 0.16497041635383572,\n",
       " 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp000': 0.849317738791423}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ewc = []\n",
    "print('Starting experiment...')\n",
    "\n",
    "for exp_id, experience in enumerate(train_stream):\n",
    "    print(\"Start of experience \", experience.current_experience)\n",
    "\n",
    "    ewc_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the current test set')\n",
    "    results_ewc.append(ewc_strategy.eval(benchmark.test_stream[exp_id]))\n",
    "\n",
    "print('Final evaluation...')\n",
    "ewc_strategy.eval(benchmark.test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [10/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [20/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [30/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [40/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [50/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [60/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [70/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [80/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [90/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [100/100]\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "from utilities import get_hessian_eigenvalues\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        # self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc = nn.Linear(input_size, output_size, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.fc1(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.fc2(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = 10      # number of input features\n",
    "hidden_size = 20     # number of hidden units\n",
    "output_size = 1      # number of output units\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()           # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy data for demonstration\n",
    "inputs = torch.randn(64, input_size)   # 64 samples, each with `input_size` features\n",
    "targets = torch.randn(64, output_size) # Corresponding targets\n",
    "learning_rate = 0.01\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    evals, evecs = get_hessian_eigenvalues(model, criterion, dataset, physical_batch_size=64)\n",
    "    evecs.transpose_(1, 0)\n",
    "    # evecs = torch.transpose(evecs)\n",
    "    print(f'evecs.shape : {evecs.shape}')\n",
    "    # print(f'proj_tensor: {proj_tensor.shape}')\n",
    "\n",
    "    # Backward pass\n",
    "    # loss.backward()  # Compute gradients\n",
    "    \n",
    "    # Manually update weights\n",
    "    with torch.no_grad():  # Ensure we don’t track these operations for gradient computation\n",
    "        grad = torch.autograd.grad(loss, inputs=model.parameters(), create_graph=True)\n",
    "        vec_grad = parameters_to_vector(grad)\n",
    "        print(f'vec_grad.shape: {vec_grad.shape}')\n",
    "        step = torch.Tensor(vec_grad.shape)\n",
    "        for vec in evecs:\n",
    "            step -= learning_rate * torch.dot(vec_grad, vec) * vec  # Update each parameter by gradient descent\n",
    "        vec_params = parameters_to_vector(model.parameters())\n",
    "        vec_params += step\n",
    "        vector_to_parameters(vec_params, model.parameters())\n",
    "        model.zero_grad()\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "\n",
    "\n",
    "# \n",
    "# loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "# for kek, lol in loader:\n",
    "#     print(kek.shape, lol.shape)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_step_bulk(model, loss, criterion, dataset, batch_size):\n",
    "    evals, evecs = get_hessian_eigenvalues(model, criterion, dataset, physical_batch_size=batch_size)\n",
    "    evecs.transpose_(1, 0)\n",
    "    \n",
    "    with torch.no_grad():  # Ensure we don’t track these operations for gradient computation\n",
    "        grad = torch.autograd.grad(loss, inputs=model.parameters(), create_graph=True)\n",
    "        vec_grad = parameters_to_vector(grad)\n",
    "        step = vec_grad.detach() \n",
    "        for vec in evecs:\n",
    "            step -= torch.dot(vec_grad, vec) * vec  # Update each parameter by gradient descent\n",
    "        vec_params = parameters_to_vector(model.parameters())\n",
    "        vec_params -= step * learning_rate\n",
    "        vector_to_parameters(vec_params, model.parameters())\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.9941\n",
      "Epoch [2/5], Loss: 1.3691\n",
      "Epoch [3/5], Loss: 0.9567\n",
      "Epoch [4/5], Loss: 0.7475\n",
      "Epoch [5/5], Loss: 0.6373\n",
      "Accuracy on the test set: 85.76%\n",
      "Started bulk-GD\n",
      "Epoch [1/5], Loss: 0.5637\n",
      "Epoch [2/5], Loss: 0.5271\n",
      "Epoch [3/5], Loss: 0.5030\n",
      "Epoch [4/5], Loss: 0.4692\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image to a 784-dimensional vector\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28 * 28  # MNIST images are 28x28 pixels\n",
    "hidden_size = 128     # Number of units in the hidden layer\n",
    "output_size = 10      # Number of classes for MNIST digits (0–9)\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Create a subset of 10% of the training dataset\n",
    "train_size = 5000  # 10% of the data\n",
    "indices = np.random.choice(len(full_train_dataset), train_size, replace=False)\n",
    "train_dataset = Subset(full_train_dataset, indices)\n",
    "\n",
    "# Use the entire test dataset for evaluation\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss = 0.0\n",
    "    batches = 0\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        sum_loss += loss.item()\n",
    "        batches += 1\n",
    "        # print(f'loss = {loss.item()}')\n",
    "    # print(f'Completed {epoch + 1}/{num_epochs}')\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {(sum_loss / batches):.4f}')\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy on the test set: {100 * correct / total:.2f}%')\n",
    "\n",
    "print('Started bulk-GD')\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss = 0\n",
    "    batches = 0\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # print(f'loss = {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "        sum_loss += loss.item()\n",
    "        batches += 1\n",
    "        dataset = TensorDataset(images, labels)\n",
    "        projected_step_bulk(model, loss, criterion, dataset, batch_size=64)   \n",
    "        \n",
    "\n",
    "        \n",
    "    # print(f'Completed {epoch + 1}/{num_epochs}')\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {(sum_loss / batches):.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy on the test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] loss = 0.9247192740440369\n",
      "Epoch [20/100] loss = 0.9071812629699707\n",
      "Epoch [30/100] loss = 0.8903387784957886\n",
      "Epoch [40/100] loss = 0.8741702437400818\n",
      "Epoch [50/100] loss = 0.8592936992645264\n",
      "Epoch [60/100] loss = 0.8450148105621338\n",
      "Epoch [70/100] loss = 0.8311337232589722\n",
      "Epoch [80/100] loss = 0.817618191242218\n",
      "Epoch [90/100] loss = 0.804565966129303\n",
      "Epoch [100/100] loss = 0.7920476198196411\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "from utilities import get_hessian_eigenvalues\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        # self.fc = nn.Linear(input_size, output_size, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = 10      # number of input features\n",
    "hidden_size = 20     # number of hidden units\n",
    "output_size = 1      # number of output units\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()           # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy data for demonstration\n",
    "inputs = torch.randn(64, input_size)   # 64 samples, each with `input_size` features\n",
    "targets = torch.randn(64, output_size) # Corresponding targets\n",
    "learning_rate = 0.01\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    projected_step_bulk(model, loss, criterion, dataset, batch_size=64)\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] loss = {loss.item()}')\n",
    "\n",
    "\n",
    "# \n",
    "# loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "# for kek, lol in loader:\n",
    "#     print(kek.shape, lol.shape)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16327fa30>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "240 * 240 * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241, 6])\n"
     ]
    }
   ],
   "source": [
    "print(evecs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
