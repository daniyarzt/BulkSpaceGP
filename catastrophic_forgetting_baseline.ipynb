{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <EEB3232B-F6A7-3262-948C-BB2F54905803> /Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/daniyarzakarin/miniconda3/envs/clenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of task  0\n",
      "Classes in this task: [0, 1, 2, 7, 8]\n",
      "Task 0\n",
      "This task contains 30739 training examples\n",
      "This task contains 5149 test examples\n",
      "Start of task  0\n",
      "Classes in this task: [3, 4, 5, 6, 9]\n",
      "Task 0\n",
      "This task contains 29261 training examples\n",
      "This task contains 4851 test examples\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitMNIST\n",
    "\n",
    "benchmark = SplitMNIST(n_experiences=2)\n",
    "\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "for experience in train_stream: \n",
    "    print(\"Start of task \", experience.task_label)\n",
    "    print('Classes in this task:', experience.classes_in_this_experience)\n",
    "\n",
    "    current_training_set = experience.dataset\n",
    "    print('Task {}'.format(experience.task_label))\n",
    "    print('This task contains', len(current_training_set), 'training examples')\n",
    "\n",
    "    current_test_set = test_stream[experience.current_experience].dataset\n",
    "    print('This task contains', len(current_test_set), 'test examples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the file logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, \\\n",
    "    accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \\\n",
    "    confusion_matrix_metrics, disk_usage_metrics, StreamConfusionMatrix\n",
    "from avalanche.logging import InteractiveLogger\n",
    "\n",
    "text_logger = InteractiveLogger()\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    StreamConfusionMatrix(num_classes=benchmark.n_classes, save_image=False),\n",
    "    loggers=[text_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models and Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive, EWC\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "mlp_naive = SimpleMLP(num_classes=benchmark.n_classes)\n",
    "naive_strategy = Naive(\n",
    "    model = mlp_naive, \n",
    "    optimizer = SGD(mlp_naive.parameters(), lr=0.001, momentum=0.9),\n",
    "    criterion = CrossEntropyLoss(), \n",
    "    train_mb_size=500, \n",
    "    train_epochs=10, \n",
    "    eval_mb_size=100,\n",
    "    evaluator=eval_plugin)\n",
    "\n",
    "mlp_ewc = SimpleMLP(num_classes=benchmark.n_classes)\n",
    "ewc_strategy = EWC(\n",
    "    model = mlp_ewc, \n",
    "    optimizer = SGD(mlp_ewc.parameters(), lr=0.001, momentum=0.9),\n",
    "    criterion = CrossEntropyLoss(), \n",
    "    ewc_lambda = 2000,\n",
    "    train_mb_size=500, \n",
    "    train_epochs=10, \n",
    "    eval_mb_size=100,\n",
    "    evaluator=eval_plugin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience  0\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2072\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4758\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6856\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9038\n",
      "100%|██████████| 62/62 [00:04<00:00, 13.11it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3935\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3483\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9033\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8912\n",
      "100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2881\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2399\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9202\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9163\n",
      "100%|██████████| 62/62 [00:04<00:00, 14.24it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2479\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2102\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9267\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9289\n",
      "100%|██████████| 62/62 [00:04<00:00, 14.51it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2211\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2259\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9324\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9372\n",
      "100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2052\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2334\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9369\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9247\n",
      "100%|██████████| 62/62 [00:04<00:00, 13.18it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1940\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1626\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9397\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9498\n",
      "100%|██████████| 62/62 [00:04<00:00, 13.66it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1837\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1776\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9425\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9498\n",
      "100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1791\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1300\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9452\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9749\n",
      "100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1725\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1756\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9582\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 38.25it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1431\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9582\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[ 969,    0,    3,    0,    0,    0,    0,    1,    7,    0],\n",
      "        [   0, 1109,    7,    0,    0,    0,    0,    2,   17,    0],\n",
      "        [  15,    7,  954,    0,    0,    0,    0,   19,   37,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1,   16,   30,    0,    0,    0,    0,  974,    7,    0],\n",
      "        [   9,    6,   16,    0,    0,    0,    0,   15,  928,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1431\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9582\n",
      "Start of experience  1\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 59/59 [00:04<00:00, 12.11it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3730\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8170\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4516\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7739\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.26it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6459\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4897\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8230\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8889\n",
      "100%|██████████| 59/59 [00:05<00:00,  9.97it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4675\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4201\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8634\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8812\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.53it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3899\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3822\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8854\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8774\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.06it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3472\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3802\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8946\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8889\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.52it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3173\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2414\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9042\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9310\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.40it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2986\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2865\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9072\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9234\n",
      "100%|██████████| 59/59 [00:04<00:00, 12.22it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2793\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2537\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9142\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9272\n",
      "100%|██████████| 59/59 [00:04<00:00, 13.25it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2665\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2649\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9161\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9157\n",
      "100%|██████████| 59/59 [00:04<00:00, 14.06it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2560\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2021\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9190\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9272\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 39.93it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2119\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9326\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0, 953,   3,  29,   4,   0,   0,  21],\n",
      "        [  0,   0,   0,   2, 929,   2,  15,   0,   0,  34],\n",
      "        [  0,   0,   0,  38,  12, 810,  21,   0,   0,  11],\n",
      "        [  0,   0,   0,   4,  17,  24, 913,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,  19,  48,  21,   2,   0,   0, 919]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.2119\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9326\n",
      "Final evaluation...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 41.03it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9489\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 5.7928\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0093\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 37.77it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2119\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9326\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,  35,   3, 879,  56,   0,   0,   7],\n",
      "        [  0,  48,   0, 990,   2,  81,  13,   0,   0,   1],\n",
      "        [  0,   0,   0, 632,  46,  31, 273,   0,   0,  50],\n",
      "        [  0,   0,   0, 953,   3,  29,   4,   0,   0,  21],\n",
      "        [  0,   0,   0,   2, 929,   2,  15,   0,   0,  34],\n",
      "        [  0,   0,   0,  38,  12, 810,  21,   0,   0,  11],\n",
      "        [  0,   0,   0,   4,  17,  24, 913,   0,   0,   0],\n",
      "        [  0,   0,   0,  72,  30,   3,   1,   0,   0, 922],\n",
      "        [  0,   0,   0, 353,  26, 425,  53,   0,   0, 117],\n",
      "        [  0,   0,   0,  19,  48,  21,   2,   0,   0, 919]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0855\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.9489\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9272030651340997,\n",
       " 'Loss_MB/train_phase/train_stream/Task000': 0.20209628343582153,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9190389938826424,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task000': 0.25599117917000264,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.009322198485142746,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp000': 5.7928380825422785,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.4572,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task000': 3.085521245234832,\n",
       " 'StreamForgetting/eval_phase/test_stream': 0.9489221208001554,\n",
       " 'ConfusionMatrix_Stream/eval_phase/test_stream': tensor([[  0,   0,   0,  35,   3, 879,  56,   0,   0,   7],\n",
       "         [  0,  48,   0, 990,   2,  81,  13,   0,   0,   1],\n",
       "         [  0,   0,   0, 632,  46,  31, 273,   0,   0,  50],\n",
       "         [  0,   0,   0, 953,   3,  29,   4,   0,   0,  21],\n",
       "         [  0,   0,   0,   2, 929,   2,  15,   0,   0,  34],\n",
       "         [  0,   0,   0,  38,  12, 810,  21,   0,   0,  11],\n",
       "         [  0,   0,   0,   4,  17,  24, 913,   0,   0,   0],\n",
       "         [  0,   0,   0,  72,  30,   3,   1,   0,   0, 922],\n",
       "         [  0,   0,   0, 353,  26, 425,  53,   0,   0, 117],\n",
       "         [  0,   0,   0,  19,  48,  21,   2,   0,   0, 919]]),\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.9325912183055041,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp001': 0.21189222126120982,\n",
       " 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp000': 0.9489221208001554}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_naive = []\n",
    "print('Starting experiment...')\n",
    "\n",
    "for exp_id, experience in enumerate(train_stream):\n",
    "    print(\"Start of experience \", experience.current_experience)\n",
    "\n",
    "    naive_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the current test set')\n",
    "    results_naive.append(naive_strategy.eval(benchmark.test_stream[exp_id]))\n",
    "\n",
    "print('Final evaluation...')\n",
    "naive_strategy.eval(benchmark.test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience  0\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.46it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2564\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5641\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6558\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8842\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.94it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4232\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3516\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8949\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9243\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.79it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3088\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2859\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9129\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9125\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.86it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2633\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2297\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9225\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9314\n",
      "100%|██████████| 61/61 [00:04<00:00, 12.43it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2391\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2044\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9272\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9433\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.21it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2211\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1789\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9327\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9456\n",
      "100%|██████████| 61/61 [00:04<00:00, 12.66it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2105\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2462\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9358\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9220\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.54it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1979\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1981\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9398\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9291\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.36it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1904\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2167\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9417\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9385\n",
      "100%|██████████| 61/61 [00:04<00:00, 13.70it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1833\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1649\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9436\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9551\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 36.97it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1416\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9575\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[ 971,    0,    3,    0,    0,    0,    0,    0,    5,    1],\n",
      "        [   0, 1114,    6,    0,    0,    0,    0,    0,   13,    2],\n",
      "        [  15,   10,  953,    0,    0,    0,    0,    0,   37,   17],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [  11,    7,   17,    0,    0,    0,    0,    0,  908,   31],\n",
      "        [   9,    8,    7,    0,    0,    0,    0,    0,   19,  966]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1416\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9575\n",
      "Start of experience  1\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.34it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6450\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8660\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4709\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8701\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.47it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6075\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5457\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8784\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8312\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.17it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4180\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4184\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9010\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8961\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.13it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3498\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4623\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9138\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8571\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.32it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3142\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2360\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9191\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9481\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.78it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2896\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9243\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9221\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.98it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2729\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2892\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9288\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8961\n",
      "100%|██████████| 60/60 [00:05<00:00, 11.50it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2566\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2481\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9336\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9481\n",
      "100%|██████████| 60/60 [00:05<00:00, 11.17it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2463\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2632\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9339\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9221\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.41it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2365\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2108\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9381\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9221\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the current test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 35.71it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1650\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9509\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0, 955,   2,  23,   4,  26,   0,   0],\n",
      "        [  0,   0,   0,   1, 955,   3,  16,   7,   0,   0],\n",
      "        [  0,   0,   0,  43,  16, 811,  18,   4,   0,   0],\n",
      "        [  0,   0,   0,   4,  12,  17, 924,   1,   0,   0],\n",
      "        [  0,   0,   0,  26,  14,   0,   2, 986,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 0.1650\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9509\n",
      "Final evaluation...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 52/52 [00:01<00:00, 32.67it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.8493\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.9334\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1082\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 49/49 [00:01<00:00, 38.22it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1650\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9509\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
      "tensor([[  0,   0,   0,  40,   1, 836,  96,   7,   0,   0],\n",
      "        [  0, 497,   0, 468,   6,  37,  11, 116,   0,   0],\n",
      "        [  0,   0,  58, 523,  65,  32, 304,  50,   0,   0],\n",
      "        [  0,   0,   0, 955,   2,  23,   4,  26,   0,   0],\n",
      "        [  0,   0,   0,   1, 955,   3,  16,   7,   0,   0],\n",
      "        [  0,   0,   0,  43,  16, 811,  18,   4,   0,   0],\n",
      "        [  0,   0,   0,   4,  12,  17, 924,   1,   0,   0],\n",
      "        [  0,   0,   0,  26,  14,   0,   2, 986,   0,   0],\n",
      "        [  0,   0,   0, 326,  37, 532,  41,  38,   0,   0],\n",
      "        [  0,   0,   0,  25, 681,  34,   4, 265,   0,   0]])\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.0982\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.8493\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Top1_Acc_MB/train_phase/train_stream/Task000': 0.922077922077922,\n",
       " 'Loss_MB/train_phase/train_stream/Task000': 0.21081849932670593,\n",
       " 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9380599790377658,\n",
       " 'Loss_Epoch/train_phase/train_stream/Task000': 0.23651596240989736,\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.10818713450292397,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp000': 3.9334067754578173,\n",
       " 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.5186,\n",
       " 'Loss_Stream/eval_phase/test_stream/Task000': 2.0981782685741783,\n",
       " 'StreamForgetting/eval_phase/test_stream': 0.849317738791423,\n",
       " 'ConfusionMatrix_Stream/eval_phase/test_stream': tensor([[  0,   0,   0,  40,   1, 836,  96,   7,   0,   0],\n",
       "         [  0, 497,   0, 468,   6,  37,  11, 116,   0,   0],\n",
       "         [  0,   0,  58, 523,  65,  32, 304,  50,   0,   0],\n",
       "         [  0,   0,   0, 955,   2,  23,   4,  26,   0,   0],\n",
       "         [  0,   0,   0,   1, 955,   3,  16,   7,   0,   0],\n",
       "         [  0,   0,   0,  43,  16, 811,  18,   4,   0,   0],\n",
       "         [  0,   0,   0,   4,  12,  17, 924,   1,   0,   0],\n",
       "         [  0,   0,   0,  26,  14,   0,   2, 986,   0,   0],\n",
       "         [  0,   0,   0, 326,  37, 532,  41,  38,   0,   0],\n",
       "         [  0,   0,   0,  25, 681,  34,   4, 265,   0,   0]]),\n",
       " 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.9509240246406571,\n",
       " 'Loss_Exp/eval_phase/test_stream/Task000/Exp001': 0.16497041635383572,\n",
       " 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp000': 0.849317738791423}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ewc = []\n",
    "print('Starting experiment...')\n",
    "\n",
    "for exp_id, experience in enumerate(train_stream):\n",
    "    print(\"Start of experience \", experience.current_experience)\n",
    "\n",
    "    ewc_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the current test set')\n",
    "    results_ewc.append(ewc_strategy.eval(benchmark.test_stream[exp_id]))\n",
    "\n",
    "print('Final evaluation...')\n",
    "ewc_strategy.eval(benchmark.test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [10/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [20/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [30/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [40/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [50/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [60/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [70/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [80/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [90/100]\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "evecs.shape : torch.Size([6, 10])\n",
      "vec_grad.shape: torch.Size([10])\n",
      "Epoch [100/100]\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "from utilities import get_hessian_eigenvalues\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        # self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc = nn.Linear(input_size, output_size, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.fc1(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.fc2(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = 10      # number of input features\n",
    "hidden_size = 20     # number of hidden units\n",
    "output_size = 1      # number of output units\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()           # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy data for demonstration\n",
    "inputs = torch.randn(64, input_size)   # 64 samples, each with `input_size` features\n",
    "targets = torch.randn(64, output_size) # Corresponding targets\n",
    "learning_rate = 0.01\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    evals, evecs = get_hessian_eigenvalues(model, criterion, dataset, physical_batch_size=64)\n",
    "    evecs.transpose_(1, 0)\n",
    "    # evecs = torch.transpose(evecs)\n",
    "    print(f'evecs.shape : {evecs.shape}')\n",
    "    # print(f'proj_tensor: {proj_tensor.shape}')\n",
    "\n",
    "    # Backward pass\n",
    "    # loss.backward()  # Compute gradients\n",
    "    \n",
    "    # Manually update weights\n",
    "    with torch.no_grad():  # Ensure we don’t track these operations for gradient computation\n",
    "        grad = torch.autograd.grad(loss, inputs=model.parameters(), create_graph=True)\n",
    "        vec_grad = parameters_to_vector(grad)\n",
    "        print(f'vec_grad.shape: {vec_grad.shape}')\n",
    "        step = torch.Tensor(vec_grad.shape)\n",
    "        for vec in evecs:\n",
    "            step -= learning_rate * torch.dot(vec_grad, vec) * vec  # Update each parameter by gradient descent\n",
    "        vec_params = parameters_to_vector(model.parameters())\n",
    "        vec_params += step\n",
    "        vector_to_parameters(vec_params, model.parameters())\n",
    "        model.zero_grad()\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "\n",
    "\n",
    "# \n",
    "# loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "# for kek, lol in loader:\n",
    "#     print(kek.shape, lol.shape)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_step_bulk(model, loss, criterion, dataset, batch_size):\n",
    "    evals, evecs = get_hessian_eigenvalues(model, criterion, dataset, physical_batch_size=batch_size)\n",
    "    evecs.transpose_(1, 0)\n",
    "    \n",
    "    with torch.no_grad():  # Ensure we don’t track these operations for gradient computation\n",
    "        grad = torch.autograd.grad(loss, inputs=model.parameters(), create_graph=True)\n",
    "        vec_grad = parameters_to_vector(grad)\n",
    "        step = vec_grad.detach() \n",
    "        for vec in evecs:\n",
    "            step -= torch.dot(vec_grad, vec) * vec  # Update each parameter by gradient descent\n",
    "        vec_params = parameters_to_vector(model.parameters())\n",
    "        vec_params -= step * learning_rate\n",
    "        vector_to_parameters(vec_params, model.parameters())\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] loss = 0.8144099712371826\n",
      "Epoch [20/100] loss = 0.8066299557685852\n",
      "Epoch [30/100] loss = 0.798613429069519\n",
      "Epoch [40/100] loss = 0.7902948260307312\n",
      "Epoch [50/100] loss = 0.7818781733512878\n",
      "Epoch [60/100] loss = 0.7729998826980591\n",
      "Epoch [70/100] loss = 0.7637898325920105\n",
      "Epoch [80/100] loss = 0.7540335059165955\n",
      "Epoch [90/100] loss = 0.7437845468521118\n",
      "Epoch [100/100] loss = 0.7331085205078125\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "from utilities import get_hessian_eigenvalues\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        # self.fc = nn.Linear(input_size, output_size, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = 10      # number of input features\n",
    "hidden_size = 20     # number of hidden units\n",
    "output_size = 1      # number of output units\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()           # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy data for demonstration\n",
    "inputs = torch.randn(64, input_size)   # 64 samples, each with `input_size` features\n",
    "targets = torch.randn(64, output_size) # Corresponding targets\n",
    "learning_rate = 0.01\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    projected_step_bulk(model, loss, criterion, dataset, batch_size=64)\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] loss = {loss.item()}')\n",
    "\n",
    "\n",
    "# \n",
    "# loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "# for kek, lol in loader:\n",
    "#     print(kek.shape, lol.shape)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.6079\n",
      "Epoch [2/5], Loss: 1.1114\n",
      "Epoch [3/5], Loss: 0.8106\n",
      "Epoch [4/5], Loss: 0.7819\n",
      "Epoch [5/5], Loss: 1.0032\n",
      "Started bulk-GD\n",
      "loss = 0.6175386905670166\n",
      "loss = 0.6685801148414612\n",
      "loss = 0.5672411918640137\n",
      "loss = 0.7241905331611633\n",
      "loss = 0.5184228420257568\n",
      "loss = 0.6765264272689819\n",
      "loss = 0.5570483207702637\n",
      "loss = 0.520581841468811\n",
      "loss = 0.6423359513282776\n",
      "loss = 0.7125670313835144\n",
      "loss = 0.5165165066719055\n",
      "loss = 0.6393201947212219\n",
      "loss = 0.7577792406082153\n",
      "loss = 0.6570294499397278\n",
      "loss = 0.7472308874130249\n",
      "loss = 0.5692609548568726\n",
      "loss = 0.606831967830658\n",
      "loss = 0.8656203746795654\n",
      "loss = 0.49272921681404114\n",
      "loss = 0.5099841356277466\n",
      "loss = 0.6835612058639526\n",
      "loss = 0.628917932510376\n",
      "loss = 0.4078996181488037\n",
      "loss = 0.5790503025054932\n",
      "loss = 0.5093106627464294\n",
      "loss = 0.5036419034004211\n",
      "loss = 0.6101067066192627\n",
      "loss = 0.5914376378059387\n",
      "loss = 0.6565431952476501\n",
      "loss = 0.6435202360153198\n",
      "loss = 0.6197502017021179\n",
      "loss = 0.6169801354408264\n",
      "loss = 0.5610014796257019\n",
      "loss = 0.6033904552459717\n",
      "loss = 0.49644550681114197\n",
      "loss = 0.6577487587928772\n",
      "loss = 0.592314600944519\n",
      "loss = 0.630875289440155\n",
      "loss = 0.4408765435218811\n",
      "loss = 0.5843454599380493\n",
      "loss = 0.610786497592926\n",
      "loss = 0.6563944220542908\n",
      "loss = 0.5061779618263245\n",
      "loss = 0.7908511161804199\n",
      "loss = 0.6450365781784058\n",
      "loss = 0.6193714737892151\n",
      "loss = 0.5302860736846924\n",
      "loss = 0.6553905606269836\n",
      "loss = 0.6668136119842529\n",
      "loss = 0.4832497537136078\n",
      "loss = 0.6206110715866089\n",
      "loss = 0.5495311617851257\n",
      "loss = 0.5522221922874451\n",
      "loss = 0.7264458537101746\n",
      "loss = 0.5132259130477905\n",
      "loss = 0.680731475353241\n",
      "loss = 0.5132167339324951\n",
      "loss = 0.5685994029045105\n",
      "loss = 0.6688123941421509\n",
      "loss = 0.5611397624015808\n",
      "loss = 0.7108832001686096\n",
      "loss = 0.6747260689735413\n",
      "loss = 0.6534860134124756\n",
      "loss = 0.529644250869751\n",
      "loss = 0.5355265140533447\n",
      "loss = 0.8724970817565918\n",
      "loss = 0.6373268961906433\n",
      "loss = 0.6469009518623352\n",
      "loss = 0.654764711856842\n",
      "loss = 0.718889057636261\n",
      "loss = 0.4808429479598999\n",
      "loss = 0.6386708617210388\n",
      "loss = 0.5445302724838257\n",
      "loss = 0.617653489112854\n",
      "loss = 0.5734543204307556\n",
      "loss = 0.4735085070133209\n",
      "loss = 0.7342351675033569\n",
      "loss = 0.8401392698287964\n",
      "loss = 0.5425785183906555\n",
      "Epoch [1/5], Loss: 0.5426\n",
      "loss = 0.5301043391227722\n",
      "loss = 0.6253248453140259\n",
      "loss = 0.6314491033554077\n",
      "loss = 0.4904818534851074\n",
      "loss = 0.5401687622070312\n",
      "loss = 0.5116349458694458\n",
      "loss = 0.6364293694496155\n",
      "loss = 0.6829351782798767\n",
      "loss = 0.6040709614753723\n",
      "loss = 0.6808183789253235\n",
      "loss = 0.5627552270889282\n",
      "loss = 0.6783486008644104\n",
      "loss = 0.6201137900352478\n",
      "loss = 0.5532019138336182\n",
      "loss = 0.6878683567047119\n",
      "loss = 0.4926764667034149\n",
      "loss = 0.4491291344165802\n",
      "loss = 0.5561528205871582\n",
      "loss = 0.6176321506500244\n",
      "loss = 0.6427271962165833\n",
      "loss = 0.6047573089599609\n",
      "loss = 0.48714447021484375\n",
      "loss = 0.5637121200561523\n",
      "loss = 0.7529495358467102\n",
      "loss = 0.620795726776123\n",
      "loss = 0.7081480026245117\n",
      "loss = 0.48159730434417725\n",
      "loss = 0.7815860509872437\n",
      "loss = 0.6016736626625061\n",
      "loss = 0.6431141495704651\n",
      "loss = 0.5613499879837036\n",
      "loss = 0.5302643179893494\n",
      "loss = 0.5882018804550171\n",
      "loss = 0.6007069945335388\n",
      "loss = 0.7239024639129639\n",
      "loss = 0.5417681932449341\n",
      "loss = 0.5984331965446472\n",
      "loss = 0.5339919924736023\n",
      "loss = 0.5314444899559021\n",
      "loss = 0.5267958641052246\n",
      "loss = 0.8362482786178589\n",
      "loss = 0.7029146552085876\n",
      "loss = 0.5583884716033936\n",
      "loss = 0.6902433037757874\n",
      "loss = 0.5352583527565002\n",
      "loss = 0.8393667936325073\n",
      "loss = 0.8309345841407776\n",
      "loss = 0.6706660389900208\n",
      "loss = 0.7759106159210205\n",
      "loss = 0.6129164099693298\n",
      "loss = 0.8277617692947388\n",
      "loss = 0.5910903811454773\n",
      "loss = 0.6275440454483032\n",
      "loss = 0.6050358414649963\n",
      "loss = 0.5324607491493225\n",
      "loss = 0.5824131965637207\n",
      "loss = 0.5022752285003662\n",
      "loss = 0.5616919994354248\n",
      "loss = 0.5794300436973572\n",
      "loss = 0.630070149898529\n",
      "loss = 0.5542762279510498\n",
      "loss = 0.6113025546073914\n",
      "loss = 0.7887486815452576\n",
      "loss = 0.5110521912574768\n",
      "loss = 0.6774907112121582\n",
      "loss = 0.719353199005127\n",
      "loss = 0.6874547600746155\n",
      "loss = 0.49233588576316833\n",
      "loss = 0.6051417589187622\n",
      "loss = 0.44744664430618286\n",
      "loss = 0.6465342044830322\n",
      "loss = 0.5192742943763733\n",
      "loss = 0.5576834678649902\n",
      "loss = 0.6577680706977844\n",
      "loss = 0.6666364669799805\n",
      "loss = 0.6484300494194031\n",
      "loss = 0.7275490760803223\n",
      "loss = 0.4271617531776428\n",
      "loss = 0.6470987796783447\n",
      "Epoch [2/5], Loss: 0.6471\n",
      "loss = 0.5359790325164795\n",
      "loss = 0.6186611652374268\n",
      "loss = 0.6562348008155823\n",
      "loss = 0.6437674164772034\n",
      "loss = 0.727331817150116\n",
      "loss = 0.5930019021034241\n",
      "loss = 0.4609903395175934\n",
      "loss = 0.527675986289978\n",
      "loss = 0.5941888093948364\n",
      "loss = 0.6517547965049744\n",
      "loss = 0.543055534362793\n",
      "loss = 0.574725866317749\n",
      "loss = 0.5746591687202454\n",
      "loss = 0.6636703610420227\n",
      "loss = 0.5692214965820312\n",
      "loss = 0.5780771970748901\n",
      "loss = 0.4432494342327118\n",
      "loss = 0.5833120942115784\n",
      "loss = 0.6315929889678955\n",
      "loss = 0.6420846581459045\n",
      "loss = 0.6419752836227417\n",
      "loss = 0.6058513522148132\n",
      "loss = 0.673413872718811\n",
      "loss = 0.5684529542922974\n",
      "loss = 0.587812602519989\n",
      "loss = 0.45510900020599365\n",
      "loss = 0.5425511002540588\n",
      "loss = 0.6976554989814758\n",
      "loss = 0.8421450257301331\n",
      "loss = 0.6906194686889648\n",
      "loss = 0.722538411617279\n",
      "loss = 0.5329834818840027\n",
      "loss = 0.6124804615974426\n",
      "loss = 0.7190645337104797\n",
      "loss = 0.6080508828163147\n",
      "loss = 0.6329074501991272\n",
      "loss = 0.5545165538787842\n",
      "loss = 0.4392164647579193\n",
      "loss = 0.5576004981994629\n",
      "loss = 0.6997280716896057\n",
      "loss = 0.6259806156158447\n",
      "loss = 0.5648742914199829\n",
      "loss = 0.6151562929153442\n",
      "loss = 0.6914789080619812\n",
      "loss = 0.8941792845726013\n",
      "loss = 0.7122572064399719\n",
      "loss = 0.5877273678779602\n",
      "loss = 0.43587610125541687\n",
      "loss = 0.5765907764434814\n",
      "loss = 0.5592457056045532\n",
      "loss = 0.6324766874313354\n",
      "loss = 0.6300430297851562\n",
      "loss = 0.6953648924827576\n",
      "loss = 0.7060353755950928\n",
      "loss = 0.6473656892776489\n",
      "loss = 0.5711567997932434\n",
      "loss = 0.7125599980354309\n",
      "loss = 0.6253091096878052\n",
      "loss = 0.48593857884407043\n",
      "loss = 0.5500690340995789\n",
      "loss = 0.7162197828292847\n",
      "loss = 0.6100767850875854\n",
      "loss = 0.6206371784210205\n",
      "loss = 0.6844865083694458\n",
      "loss = 0.5735777616500854\n",
      "loss = 0.5586021542549133\n",
      "loss = 0.6783453226089478\n",
      "loss = 0.6117967963218689\n",
      "loss = 0.4824203848838806\n",
      "loss = 0.7494542002677917\n",
      "loss = 0.5674073696136475\n",
      "loss = 0.6697912812232971\n",
      "loss = 0.5464881658554077\n",
      "loss = 0.6069012880325317\n",
      "loss = 0.6246399879455566\n",
      "loss = 0.5527328252792358\n",
      "loss = 0.753783106803894\n",
      "loss = 0.6386957168579102\n",
      "loss = 0.47252005338668823\n",
      "Epoch [3/5], Loss: 0.4725\n",
      "loss = 0.5672548413276672\n",
      "loss = 0.7121996879577637\n",
      "loss = 0.5534921288490295\n",
      "loss = 0.5897084474563599\n",
      "loss = 0.5781158208847046\n",
      "loss = 0.6555347442626953\n",
      "loss = 0.5493653416633606\n",
      "loss = 0.7624602913856506\n",
      "loss = 0.5337443351745605\n",
      "loss = 0.5496131181716919\n",
      "loss = 0.4398360252380371\n",
      "loss = 0.5580824017524719\n",
      "loss = 0.5430225133895874\n",
      "loss = 0.6274605393409729\n",
      "loss = 0.6022060513496399\n",
      "loss = 0.6526498794555664\n",
      "loss = 0.5853736996650696\n",
      "loss = 0.5863837599754333\n",
      "loss = 0.6393701434135437\n",
      "loss = 0.6931769251823425\n",
      "loss = 0.6017990112304688\n",
      "loss = 0.8067237734794617\n",
      "loss = 0.6174240708351135\n",
      "loss = 0.5272047519683838\n",
      "loss = 0.7288658618927002\n",
      "loss = 0.7255865335464478\n",
      "loss = 0.6334046125411987\n",
      "loss = 0.648137092590332\n",
      "loss = 0.6164031624794006\n",
      "loss = 0.4851473867893219\n",
      "loss = 0.5864266157150269\n",
      "loss = 0.5893514752388\n",
      "loss = 0.5385369658470154\n",
      "loss = 0.5857352018356323\n",
      "loss = 0.4652708172798157\n",
      "loss = 0.5676614046096802\n",
      "loss = 0.5596566200256348\n",
      "loss = 0.7592498660087585\n",
      "loss = 0.4834786057472229\n",
      "loss = 0.5127896070480347\n",
      "loss = 0.614353358745575\n",
      "loss = 0.5953207612037659\n",
      "loss = 0.4924698770046234\n",
      "loss = 0.7218849658966064\n",
      "loss = 0.6171796917915344\n",
      "loss = 0.7350217700004578\n",
      "loss = 0.6236305236816406\n",
      "loss = 0.5233293175697327\n",
      "loss = 0.6079167127609253\n",
      "loss = 0.5059154033660889\n",
      "loss = 0.5205167531967163\n",
      "loss = 0.5261216163635254\n",
      "loss = 0.6433964967727661\n",
      "loss = 0.6198298335075378\n",
      "loss = 0.6634287238121033\n",
      "loss = 0.5456607937812805\n",
      "loss = 0.6730537414550781\n",
      "loss = 0.487589031457901\n",
      "loss = 0.7585023641586304\n",
      "loss = 0.669305145740509\n",
      "loss = 0.6033110618591309\n",
      "loss = 0.4953440725803375\n",
      "loss = 0.6075459122657776\n",
      "loss = 0.718157172203064\n",
      "loss = 0.5075255036354065\n",
      "loss = 0.7269741892814636\n",
      "loss = 0.7024639844894409\n",
      "loss = 0.8268986344337463\n",
      "loss = 0.5928880572319031\n",
      "loss = 0.6495653986930847\n",
      "loss = 0.7679102420806885\n",
      "loss = 0.6771965026855469\n",
      "loss = 0.571016788482666\n",
      "loss = 0.5298575758934021\n",
      "loss = 0.7056728601455688\n",
      "loss = 0.7082430720329285\n",
      "loss = 0.6298137307167053\n",
      "loss = 0.4844396710395813\n",
      "loss = 0.4362320005893707\n",
      "Epoch [4/5], Loss: 0.4362\n",
      "loss = 0.7020400762557983\n",
      "loss = 0.49295905232429504\n",
      "loss = 0.6837834119796753\n",
      "loss = 0.589733362197876\n",
      "loss = 0.35580477118492126\n",
      "loss = 0.5599610209465027\n",
      "loss = 0.612397313117981\n",
      "loss = 0.6097641587257385\n",
      "loss = 0.5420041680335999\n",
      "loss = 0.5692296028137207\n",
      "loss = 0.6732350587844849\n",
      "loss = 0.613806426525116\n",
      "loss = 0.46946483850479126\n",
      "loss = 0.558809757232666\n",
      "loss = 0.7418160438537598\n",
      "loss = 0.5874515175819397\n",
      "loss = 0.7016966342926025\n",
      "loss = 0.7208423614501953\n",
      "loss = 0.6261204481124878\n",
      "loss = 0.5939419865608215\n",
      "loss = 0.5223177671432495\n",
      "loss = 0.763283371925354\n",
      "loss = 0.6222800016403198\n",
      "loss = 0.6462208032608032\n",
      "loss = 0.5497217178344727\n",
      "loss = 0.49759647250175476\n",
      "loss = 0.599185585975647\n",
      "loss = 0.615440309047699\n",
      "loss = 0.5500043034553528\n",
      "loss = 0.7326643466949463\n",
      "loss = 0.6004010438919067\n",
      "loss = 0.6440352201461792\n",
      "loss = 0.6915860772132874\n",
      "loss = 0.6808313727378845\n",
      "loss = 0.8359141945838928\n",
      "loss = 0.5912762880325317\n",
      "loss = 0.6005909442901611\n",
      "loss = 0.6095815896987915\n",
      "loss = 0.5836566686630249\n",
      "loss = 0.5827599763870239\n",
      "loss = 0.6422707438468933\n",
      "loss = 0.5027113556861877\n",
      "loss = 0.5553757548332214\n",
      "loss = 0.42493459582328796\n",
      "loss = 0.616912841796875\n",
      "loss = 0.7661645412445068\n",
      "loss = 0.5143235325813293\n",
      "loss = 0.6561810374259949\n",
      "loss = 0.7238806486129761\n",
      "loss = 0.562414288520813\n",
      "loss = 0.5673158764839172\n",
      "loss = 0.6044212579727173\n",
      "loss = 0.658011794090271\n",
      "loss = 0.7204692363739014\n",
      "loss = 0.6896365880966187\n",
      "loss = 0.5786008238792419\n",
      "loss = 0.6511146426200867\n",
      "loss = 0.6473230123519897\n",
      "loss = 0.6294079422950745\n",
      "loss = 0.7021030783653259\n",
      "loss = 0.5933040380477905\n",
      "loss = 0.5262433290481567\n",
      "loss = 0.7528681755065918\n",
      "loss = 0.6106340885162354\n",
      "loss = 0.4848100244998932\n",
      "loss = 0.6116940379142761\n",
      "loss = 0.4047255516052246\n",
      "loss = 0.6719270944595337\n",
      "loss = 0.6050260066986084\n",
      "loss = 0.38877245783805847\n",
      "loss = 0.5842822790145874\n",
      "loss = 0.5790385007858276\n",
      "loss = 0.5523836016654968\n",
      "loss = 0.5601103901863098\n",
      "loss = 0.6291772723197937\n",
      "loss = 0.5473251938819885\n",
      "loss = 0.7507962584495544\n",
      "loss = 0.5920366048812866\n",
      "loss = 0.5259225368499756\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image to a 784-dimensional vector\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28 * 28  # MNIST images are 28x28 pixels\n",
    "hidden_size = 128     # Number of units in the hidden layer\n",
    "output_size = 10      # Number of classes for MNIST digits (0–9)\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Create a subset of 10% of the training dataset\n",
    "train_size = 5000  # 10% of the data\n",
    "indices = np.random.choice(len(full_train_dataset), train_size, replace=False)\n",
    "train_dataset = Subset(full_train_dataset, indices)\n",
    "\n",
    "# Use the entire test dataset for evaluation\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        # print(f'loss = {loss.item()}')\n",
    "    # print(f'Completed {epoch + 1}/{num_epochs}')\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Started bulk-GD')\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss = torch.tensor(0.0)\n",
    "    batches = 0\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(f'loss = {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "        sum_loss += loss\n",
    "        batches += 1\n",
    "        \n",
    "    print(f'average_loss: {sum_loss / batches}')\n",
    "    projected_step_bulk(model, sum_loss, criterion, train_dataset, batch_size=64)\n",
    "\n",
    "        \n",
    "    # print(f'Completed {epoch + 1}/{num_epochs}')\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy on the test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17582df30>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "240 * 240 * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241, 6])\n"
     ]
    }
   ],
   "source": [
    "print(evecs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
